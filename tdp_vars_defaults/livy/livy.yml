---
# Livy version
livy_release: apache-livy-0.8.0-incubating-TDP-0.1.0-SNAPSHOT-bin
livy_dist_file: "{{ livy_release }}.zip"

# Spark version ('spark2' or 'spark3')
spark_version: spark2

# Livy user and group
livy_user: livy
hadoop_group: hadoop

# Livy installation directory
livy_root_dir: /opt/tdp
livy_install_dir: "{{ livy_root_dir }}/livy"

# Livy configuration directories
livy_root_conf_dir: /etc/livy
livy_server_conf_dir: "{{ livy_root_conf_dir }}/conf.server"

# Livy pid directory
livy_pid_dir: /var/run/livy

# Properties
hadoop_home: /opt/tdp/hadoop
hadoop_conf_dir: /etc/hadoop/conf
spark_home: /opt/tdp/spark
spark_conf_dir: /etc/spark/conf
java_home: /usr/lib/jvm/jre-1.8.0-openjdk

# Kerberos
###
# Set to 'no' to skip service principals and keytabs creation.
# This can be useful if TDP operators don't have admin access to the Kerberos server,
# or if the Kerberos server does not support MIT Kerberos tools.
###
krb_create_principals_keytabs: yes

# SSL Keystore and Truststore
livy_keystore_location: /etc/ssl/certs/keystore.jks
livy_keystore_password: Keystore123!

livy_server_port: "{{ livy_spark2_server_port }}"

# livy.conf
livy_conf:
  livy.keystore: "{{ livy_keystore_location }}"
  livy.keystore.password: "{{ livy_keystore_password }}"
  livy.server.auth.type: kerberos
  livy.server.auth.kerberos.principal: "HTTP/_HOST@{{ realm }}"
  livy.server.auth.kerberos.keytab: /etc/security/keytabs/spnego.service.keytab
  livy.server.launch.kerberos.principal: "livy/_HOST@{{ realm }}"
  livy.server.launch.kerberos.keytab: /etc/security/keytabs/livy.service.keytab
  livy.impersonation.enabled: true
  livy.server.port: "{{ livy_server_port }}"
  livy.server.session.timeout: 3600000
  livy.spark.master: yarn
  livy.spark.deploy-mode: cluster
  livy.repl.enable-hive-context: "true"
  livy.superusers: "hue,livy,knox"

# livy-env.sh
livy_env:
  JAVA_HOME: /usr/lib/jvm/jre-1.8.0-openjdk
  HADOOP_HOME: "{{ hadoop_home }}"
  HADOOP_CONF_DIR: "{{ hadoop_conf_dir }}"
  SPARK_HOME: "{{ spark_home }}"
  SPARK_CONF_DIR: "{{ spark_conf_dir }}"
  LD_LIBRARY_PATH: "$HADOOP_HOME/lib/native/:$LD_LIBRARY_PATH"
  LIVY_CONF_DIR: "{{ livy_server_conf_dir }}"
  LIVY_LOG_DIR: "{{ livy_log_dir }}"
  LIVY_PID_DIR: "{{ livy_pid_dir }}"

# Livy logging configuration
# Root logger level should be: [FATAL| ERROR| WARN| INFO| DEBUG| TRACE]
livy_log_dir: /var/log/livy
livy_log_file: "livy_server_{{ ansible_fqdn }}.log"
livy_root_logger_level: INFO
# Root logger should be: [RFA | DRFA]  
livy_root_logger: RFA
# Common appenders config
livy_log_layout_pattern: "%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n"
# DRFA appenders config
livy_log_drfa_date_pattern: "'.'yyyy-MM-dd"
# RFA appenders config
livy_log_rfa_maxfilesize: 256MB
livy_log_rfa_maxbackupindex: 10

# Service start on boot policies
livy_start_on_boot: no

# Service restart policies
livy_restart: "no"
