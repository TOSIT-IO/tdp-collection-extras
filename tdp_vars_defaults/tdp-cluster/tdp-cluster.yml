# Copyright 2022 TOSIT.IO
# SPDX-License-Identifier: Apache-2.0

---

tdp_extra_root_dir: "{{ tdp_root_dir }}"
#############################
# Service & Component ports #
#############################

# hue ports
hue_web_http_port: 8888

# Jupyterhub ports
jupyterhub_http_port: 8000
jupyterhub_hub_http_port: 8081

# Livy-spark3 ports
livy_spark3_server_port: 8999

# Exporter ports
exporter_livy_spark3_http_port: 18204
exporter_livy_spark3_jmxremote_username: "{{ jmxremote_username }}"
exporter_livy_spark3_jmxremote_password: "{{ jmxremote_password }}"
#################################
# Service & Component logs dirs #
#################################
tdp_date_iso8601_with_tz_enable: true
# If tdp_date_iso8601_with_tz_enable is false, %(asctime)s will be formatted with following pattern :
tdp_python_date_pattern: "%Y-%m-%dT%H:%M:%S.%f%z"
tdp_python_log_layout_pattern: "%(asctime)s - %(levelname)s - %(name)s - %(funcName)s:%(lineno)d - %(message)s"

hue_log_dir: /var/log/hue
hue_log_file: "hue_server_%PROC_NAME%_{{ ansible_fqdn }}.log"
hue_collected_log: "hue_server_error_{{ ansible_fqdn }}.log"

jupyterhub_log_dir: /var/log/jupyterhub
jupyterhub_log_file: "jupyterhub_server_{{ ansible_fqdn }}.log"

livy_spark3_log_dir: /var/log/livy-spark3
livy_spark3_log_file: "livy-spark3_server_{{ ansible_fqdn }}.log"

#
# Observability
#
observability_tdp_targets:
  livy_spark3:
    unix_group: "{{ hadoop_group }}"
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers | default('') }}"
    server:
      jobs:
        - log_file: "{{ livy_spark3_log_dir }}/{{ livy_spark3_log_file }}"
          exporter_port: "{{ exporter_livy_spark3_http_port }}"
          prometheus_scrape_options:
            scheme: https
            tls_config:
              ca_file: "{{ ca_file }}"
            basic_auth:
              username: "{{ exporter_livy_spark3_jmxremote_username }}"
              password: "{{ exporter_livy_spark3_jmxremote_password }}"

  jupyter:
    unix_group: "{{ hadoop_group }}"
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_python | default('') }}"
    hub:
      jobs:
        - log_file: "{{ jupyterhub_log_dir }}/{{ jupyterhub_log_file }}"
        - exporter_port: "{{ jupyterhub_http_port }}"
          prometheus_scrape_options:
            scheme: https
            tls_config:
              ca_file: "{{ ca_file }}"

  hue:
    unix_group: "{{ hadoop_group }}"
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_python | default('') }}"
    server:
      jobs:
        - log_file: "{{ hue_log_dir }}/{{ hue_collected_log }}"
          alloy_pipeline:
          - multiline:
              firstline: '^\\d{4}-\\d{2}-\\d{2}[T]\\d{2}:\\d{2}:\\d{2}[.]\\d{3}'
          - regex:
              expression: '^(?P<datetime>.*?) - (?P<level>[A-Z]+)\\s*- .*'
          - template:
              source: 'level'
              template: "{{ '{{ ToLower .Value }}' }}"
          - timestamp:
              format: '2006-01-02T15:04:05.000000-0700'
              source: 'datetime'
          - labels:
              values:
                level: ""
        - exporter_port: "{{ hue_web_http_port }}"
          prometheus_scrape_options:
            scheme: https
            tls_config:
              ca_file: "{{ ca_file }}"
