from airflow import DAG
from airflow.operators.hive_operator import HiveOperator
from airflow.contrib.operators.hive_operator import HiveServer2Operator
from airflow.contrib.hooks.hive_server2_hook import HiveServer2Hook
from airflow.hooks.base_hook import BaseHook
from airflow.utils.dates import days_ago

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': days_ago(1),
}

dag = DAG(
    'example_hive_operator',
    default_args=default_args,
    description='A simple tutorial DAG',
    schedule_interval=None,
)

kerberos_ticket = KerberosTicket(cache='/tmp/krb5cc_123')

# Set the necessary Kerberos authentication settings
kerberos_conn_id = 'kerberos_default'
kerberos_hook = KerberosHook(krb5_conn_id=kerberos_conn_id)

# Set the HiveServer2 connection settings
hiveserver2_conn_id = 'hiveserver2_default'
hiveserver2_hook = HiveServer2Hook(hiveserver2_conn_id)

# Beeline command to connect to Hive through ZooKeeper
beeline_command = "/opt/tdp/hive/bin/beeline -u '{0}' --silent=true --showHeader=false --outputformat=csv2 --showWarnings=false --force=true"

# Example HiveOperator task
hive_query = "SELECT * FROM tdp_user_db.taxi_trip_ext LIMIT 3"
hive_operator = HiveOperator(
    task_id='example_hive_operator',
    hql=hive_query,
    hive_cli_conn_id=hiveserver2_conn_id,
    dag=dag,
)

# Example HiveServer2Operator task
hiveserver2_query = "SELECT * FROM tdp_user_db.taxi_trip_ext LIMIT 3"
hiveserver2_operator = HiveServer2Operator(
    task_id='example_hiveserver2_operator',
    hql=hiveserver2_query,
    hive_cli_conn_id=hiveserver2_conn_id,
    kerberos_ticket=kerberos_ticket,
    kerberos_service_name='hive',
    dag=dag,
)

hive_operator >> hiveserver2_operator
