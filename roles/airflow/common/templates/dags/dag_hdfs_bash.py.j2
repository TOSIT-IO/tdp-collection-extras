{% raw %}
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta


default_args = {
    'owner': 'tdp_user',
    'depends_on_past': False,
    'start_date': datetime(2023, 5, 1),
    'run_as_user': 'tdp_user',
    'queue': 'edge'
}

dag = DAG(
    dag_id='hdfs_bash',
    default_args=default_args,
    schedule_interval='0 4 * * *',  # Executes at 04:00 every day
    catchup=False,
    tags=['bash'],
)

# Retreive the active name node task
list_task = BashOperator(
    task_id='list_hdfs',
    bash_command='hdfs dfs -ls /user/',
    env={"KRB5CCNAME": "/tmp/krb5cc_1101"},
    dag=dag
)


list_task 

{% endraw %}