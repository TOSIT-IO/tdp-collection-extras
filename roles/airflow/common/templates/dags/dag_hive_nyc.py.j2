from airflow import DAG
from airflow.providers.apache.hive.operators.hive import HiveOperator
from airflow.providers.apache.hive.hooks.hive import HiveServer2Hook
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator
from airflow.utils.dates import days_ago
from datetime import datetime, timedelta
import subprocess

default_args = {
    'owner': 'tdp_user',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'hive_taxi_dag',
    default_args=default_args,
    description='A simple tutorial DAG',
    schedule_interval=None,
)

create_database = HiveOperator(
    task_id='create_database',
    hql='DROP DATABASE IF EXISTS tdp_user_db CASCADE; CREATE DATABASE IF NOT EXISTS tdp_user_db LOCATION "/warehouse/tablespace/external/hive";',
    hive_cli_conn_id='hiveserver2_tdp',
    dag=dag,
)

create_table = HiveOperator(
    task_id='create_table',
    hql='''CREATE EXTERNAL TABLE tdp_user_db.taxi_trip_ext (
        VendorID INT,
        lpep_pickup_datetime STRING,
        lpep_dropoff_datetime STRING,
        store_and_fwd_flag STRING,
        RatecodeID DOUBLE,
        PULocationID INT,
        DOLocationID INT,
        passenger_count DOUBLE,
        trip_distance DOUBLE,
        fare_amount DOUBLE,
        extra DOUBLE,
        mta_tax DOUBLE,
        tip_amount DOUBLE,
        tolls_amount DOUBLE,
        ehail_fee STRING,
        improvement_surcharge DOUBLE,
        total_amount DOUBLE,
        payment_type DOUBLE,
        trip_type DOUBLE,
        congestion_surcharge DOUBLE)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ","
    STORED AS PARQUET
    LOCATION "data/nyc_green_taxi_trip";''',
    hive_cli_conn_id='hiveserver2_tdp',
    dag=dag,
)

hive_query = "SELECT * FROM tdp_user_db.taxi_trip_ext LIMIT 3"
hive_operator = HiveOperator(
    task_id='example_hive_operator',
    hql=hive_query,
    hive_cli_conn_id='hiveserver2_tdp',
    dag=dag,
)

create_database >> create_table >> hive_operator
