#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
from typing import Callable, List

from airflow.configuration import conf
from airflow.exceptions import AirflowClusterPolicyViolation
from airflow.models.baseoperator import BaseOperator
from airflow.models import DAG
import inspect
import re


def get_current_user(task) -> str:
    # TODO: function to retreive the current_user from airflow webserver
    username = task.owner

    return username

# [START dag policy]

queues = {"tdp_user": "edge", 
         "smoke_user": "edge"}



def validate_dag_name(dag: DAG):
    for task in dag.tasks:
        if not dag.dag_id.startswith(task.owner):
            raise AirflowClusterPolicyViolation(
                                f"The DAG ID must start with the name of the owner. Current value: {dag.dag_id}"
                            )

def validate_dag_owner(dag: DAG):
    for task in dag.tasks:
        if not task.owner or task.owner.lower() == conf.get('operators',
                                                        'default_owner'):
            raise AirflowClusterPolicyViolation(
                f"""DAG {dag.dag_id} must have a valid owner. Current value: {task.owner}"""
            )

def validate_run_as_user(dag: DAG):
    for task in dag.tasks:
        if task.run_as_user and task.run_as_user != task.owner:
            raise AirflowClusterPolicyViolation(
                f"""run_as_user must be same as DAG owner. Current owner: {task.owner} | current run_as_user: {task.run_as_user}"""
            )

def validate_run_as_user_queue(dag: DAG):
    
    for task in dag.tasks:
        if task.run_as_user:
            if task.queue not in queues[task.run_as_user]:
                raise AirflowClusterPolicyViolation(
                    f"DAG {dag.dag_id} with impersonation cannot submit tasks to the queue: {task.queue}"
                )
        if hasattr(task, 'run_as_owner'):
            if task.run_as_owner:
                if task.queue not in queues[task.run_as_user]:
                    raise AirflowClusterPolicyViolation(
                        f"DAG {dag.dag_id} with impersonation cannot submit tasks to the queue: {task.queue}"
                    )

def validate_run_as_user_access_control(dag: DAG):
    for task in dag.tasks:
        if task.run_as_user:
            dag_edit_roles = [key for key, value in dag.access_control.items() if "can_edit" in value or "can_dag_edit" in value]
            if any(role != task.owner for role in dag_edit_roles):
                raise AirflowClusterPolicyViolation(
                    f"DAGs with impersonation must be edited only by the DAG owner. Current owner : {task.owner} | can_edit users: {dag_edit_roles}"
                )

        if hasattr(task, 'run_as_owner'):
            if task.run_as_owner:
                dag_edit_roles = [key for key, value in dag.access_control.items() if "can_edit" in value or "can_dag_edit" in value]
                if any(role != task.owner for role in dag_edit_roles):
                    raise AirflowClusterPolicyViolation(
                        f"DAGs with impersonation must be edited only by the DAG owner. Current owner : {task.owner} | can_edit users: {dag_edit_roles}"
                    )

def validate_spark_proxy_user(dag: DAG):
    for task in dag.tasks:
        if hasattr(task, '_proxy_user'):
            if task._proxy_user and task._proxy_user != task.owner:
                raise AirflowClusterPolicyViolation(
                    f"proxy_user must be the same as DAG owner. Current owner: {task.owner} | current proxy_user: {task._proxy_user}"
                )

def validate_WebHDFSHook_proxy_user(dag: DAG):
    # TODO : validate proxy_user in WebHDFSHook hook
    pass

DAG_RULES: List[Callable[[DAG], None]] = [
    validate_dag_name,
    validate_dag_owner,
    validate_run_as_user,
    validate_run_as_user_queue,
    validate_run_as_user_access_control,
    validate_spark_proxy_user,
    validate_WebHDFSHook_proxy_user,

]

def _check_dag_rules(current_dag: DAG):
    """Check dag rules for given task."""
    notices = []
    for rule in DAG_RULES:
        try:
            rule(current_dag)
        except AirflowClusterPolicyViolation as ex:
            notices.append(str(ex))
    if notices:
        notices_list = " * " + "\n * ".join(notices)
        raise AirflowClusterPolicyViolation(
            f"DAG policy violation (DAG ID: {current_dag.dag_id}, Path: {current_dag.filepath}):\n"
            f"Notices:\n"
            f"{notices_list}")

def dag_policy(dag: DAG):
    _check_dag_rules(dag)
